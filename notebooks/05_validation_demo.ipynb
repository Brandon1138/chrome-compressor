{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Validation Demo\n",
        "\n",
        "This notebook demonstrates bootstrap confidence intervals and sensitivity analysis for entropy estimates, following best practices in NLP evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from reducelang.validation import (\n",
        "    block_bootstrap,\n",
        "    compute_bootstrap_ci,\n",
        "    run_ablation_study,\n",
        "    format_sensitivity_results,\n",
        ")\n",
        "from reducelang.models import UnigramModel, NGramModel, PPMModel\n",
        "from reducelang.alphabet import ENGLISH_ALPHABET, ROMANIAN_ALPHABET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bootstrap overview\n",
        "\n",
        "Bootstrap resampling estimates the sampling distribution of a statistic (here, bits/char) by repeatedly resampling the data with replacement. Block bootstrap preserves temporal dependencies in text by resampling contiguous blocks rather than individual characters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "# Load a small English corpus sample (adjust the path as needed)\n",
        "corpus_file = Path(\"data/corpora/en/2025-10-01/processed/text8.txt\")\n",
        "text = corpus_file.read_text(encoding=\"utf-8\")[:50000]\n",
        "\n",
        "split_idx = int(len(text) * 0.8)\n",
        "train_text = text[:split_idx]\n",
        "test_text = text[split_idx:]\n",
        "\n",
        "model = PPMModel(ENGLISH_ALPHABET, depth=5)\n",
        "model.fit(ENGLISH_ALPHABET.normalize(train_text))\n",
        "bpc = model.evaluate(ENGLISH_ALPHABET.normalize(test_text))\n",
        "print(f\"Point estimate: {bpc:.4f} bpc\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bootstrap demonstration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "bootstrap_results = block_bootstrap(\n",
        "    text=ENGLISH_ALPHABET.normalize(test_text),\n",
        "    model=model,\n",
        "    block_size=2000,\n",
        "    n_resamples=100,\n",
        "    confidence_level=0.95,\n",
        "    seed=42,\n",
        ")\n",
        "print(f\"Mean: {bootstrap_results['mean_bpc']:.4f} bpc\")\n",
        "print(f\"Std: {bootstrap_results['std_bpc']:.4f} bpc\")\n",
        "print(\n",
        "    f\"95% CI: [{bootstrap_results['ci_lower_bpc']:.4f}, {bootstrap_results['ci_upper_bpc']:.4f}]\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "redundancy_ci = compute_bootstrap_ci(\n",
        "    bits_per_char=bpc,\n",
        "    log2_alphabet_size=ENGLISH_ALPHABET.log2_size,\n",
        "    bootstrap_results=bootstrap_results,\n",
        ")\n",
        "print(f\"Redundancy: {redundancy_ci['redundancy']:.2%}\")\n",
        "print(\n",
        "    f\"95% CI: [{redundancy_ci['ci_lower_redundancy']:.2%}, {redundancy_ci['ci_upper_redundancy']:.2%}]\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "ax.axvline(bpc, color='red', linestyle='--', label='Point estimate')\n",
        "ax.axvline(bootstrap_results['ci_lower_bpc'], color='blue', linestyle=':', label='95% CI')\n",
        "ax.axvline(bootstrap_results['ci_upper_bpc'], color='blue', linestyle=':')\n",
        "ax.set_xlabel('Bits per character')\n",
        "ax.set_title('Bootstrap Confidence Interval')\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sensitivity analysis overview\n",
        "\n",
        "Sensitivity analysis tests how robust entropy estimates are to preprocessing choices. For Romanian, we test the effect of removing diacritics. For all languages, we test removing space from the alphabet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "# Romanian sample (adjust path as needed)\n",
        "corpus_file_ro = Path(\"data/corpora/ro/2025-10-01/processed/opus.txt\")\n",
        "text_ro = corpus_file_ro.read_text(encoding=\"utf-8\")[:50000]\n",
        "split_idx_ro = int(len(text_ro) * 0.8)\n",
        "train_text_ro = text_ro[:split_idx_ro]\n",
        "test_text_ro = text_ro[split_idx_ro:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "sensitivity_results = run_ablation_study(\n",
        "    model_class=PPMModel,\n",
        "    alphabet=ROMANIAN_ALPHABET,\n",
        "    train_text=train_text_ro,\n",
        "    test_text=test_text_ro,\n",
        "    model_kwargs={\"depth\": 5, \"escape_method\": \"A\"},\n",
        "    ablations=[\"no_diacritics\", \"no_space\"],\n",
        ")\n",
        "print(f\"Baseline: {sensitivity_results['baseline']['bits_per_char']:.4f} bpc\")\n",
        "for variant in sensitivity_results['variants']:\n",
        "    print(f\"{variant['name']}: {variant['bits_per_char']:.4f} bpc (Δ={variant['delta_bpc']:+.4f}, ΔR={variant['delta_redundancy']:+.2%})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "from IPython.display import Markdown\n",
        "\n",
        "sensitivity_table = format_sensitivity_results(sensitivity_results, output_format=\"markdown\")\n",
        "Markdown(sensitivity_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "variants = ['Baseline'] + [v['name'] for v in sensitivity_results['variants']]\n",
        "bpcs = [sensitivity_results['baseline']['bits_per_char']] + [v['bits_per_char'] for v in sensitivity_results['variants']]\n",
        "redundancies = [sensitivity_results['baseline']['redundancy']] + [v['redundancy'] for v in sensitivity_results['variants']]\n",
        "ax1.bar(variants, bpcs, color=['blue'] + ['orange'] * (len(variants)-1))\n",
        "ax1.set_ylabel('Bits per character')\n",
        "ax1.set_title('Entropy by Variant')\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax2.bar(variants, [r * 100 for r in redundancies], color=['blue'] + ['green'] * (len(variants)-1))\n",
        "ax2.set_ylabel('Redundancy (%)')\n",
        "ax2.set_title('Redundancy by Variant')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Interpretation\n",
        "\n",
        "Removing diacritics from Romanian often increases entropy, showing diacritics carry information. Removing space typically increases entropy more, indicating word boundaries are informative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary\n",
        "\n",
        "Bootstrap confidence intervals quantify uncertainty in entropy estimates. Sensitivity analysis tests robustness to preprocessing choices. Both should be reported alongside point estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%\n",
        "output = {\"bootstrap\": bootstrap_results, \"sensitivity\": sensitivity_results}\n",
        "with open(\"validation_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(output, f, indent=2)\n",
        "print(\"Results saved to validation_results.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
