{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Corpus Management Demo\n",
        "\n",
        "This notebook demonstrates downloading and preprocessing corpora using the `reducelang.corpus` module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "from reducelang.corpus import CORPUS_REGISTRY, download_corpus, preprocess_corpus, generate_datacard\n",
        "from reducelang.corpus.extractors import get_extractor\n",
        "from reducelang.corpus.registry import list_corpora, get_corpus_spec\n",
        "from reducelang.alphabet import ENGLISH_ALPHABET, ROMANIAN_ALPHABET\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The corpus registry maps `(language, corpus_name)` to specifications including URLs, formats, and licenses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Available corpora:\")\n",
        "for lang, corpus in list_corpora():\n",
        "    print(f\"  {lang}/{corpus}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download a small English corpus (text8) to demonstrate the workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "spec = get_corpus_spec(\"en\", \"text8\")\n",
        "raw_path = Path(\"data/corpora/en/latest/raw/text8/text8.zip\")\n",
        "raw_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "download_corpus(spec.url, raw_path, spec.sha256)\n",
        "print(f\"Downloaded to {raw_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocess the corpus using the configured English alphabet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "extractor = get_extractor(spec.extractor_class)\n",
        "output_path = Path(\"data/corpora/en/latest/processed/text8.txt\")\n",
        "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "metadata = preprocess_corpus(raw_path, output_path, ENGLISH_ALPHABET, extractor)\n",
        "print(f\"Processed {metadata['char_count']} characters\")\n",
        "print(f\"Coverage: {metadata['coverage']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate a data card documenting the corpus snapshot and preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datacard_path = Path(\"data/corpora/en/latest/processed/text8_datacard.json\")\n",
        "from reducelang.corpus.datacard import generate_datacard\n",
        "generate_datacard(corpus_spec=spec, metadata=metadata, output_path=datacard_path, snapshot_date=\"latest\")\n",
        "import json\n",
        "print(json.dumps(json.loads(datacard_path.read_text(encoding='utf-8')), indent=2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This demonstrates the full corpus management pipeline: download → extract → normalize → document. The CLI command `reducelang prep` automates this workflow.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
